{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from typing import Dict, Optional, Any\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchgeo.datasets import EuroSAT\n",
    "from torchgeo.datamodules import NonGeoDataModule\n",
    "from torchgeo.transforms import AugmentationSequential, indices\n",
    "from torchgeo.trainers import ClassificationTask\n",
    "from torchgeo.models import ResNet18_Weights, ResNet50_Weights\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "seed_everything(543)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on all bands - experiment with model params, pretrained weights etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## torchgeo implementation with mean and std nullified\n",
    "\n",
    "class EuroSATDataModule(NonGeoDataModule):\n",
    "    \"\"\"LightningDataModule implementation for the EuroSAT dataset.\n",
    "\n",
    "    Uses the train/val/test splits from the dataset.\n",
    "\n",
    "    .. versionadded:: 0.2\n",
    "    \"\"\"\n",
    "\n",
    "    mean = torch.zeros(13)\n",
    "    std = torch.ones(13)\n",
    "\n",
    "    def __init__(\n",
    "        self, batch_size: int = 64, num_workers: int = 0, **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a new EuroSATDataModule instance.\n",
    "\n",
    "        Args:\n",
    "            batch_size: Size of each mini-batch.\n",
    "            num_workers: Number of workers for parallel data loading.\n",
    "            **kwargs: Additional keyword arguments passed to\n",
    "                :class:`~torchgeo.datasets.EuroSAT`.\n",
    "        \"\"\"\n",
    "        super().__init__(EuroSAT, batch_size, num_workers, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    batch_size = 128\n",
    "    num_workers = 8\n",
    "elif device ==  \"cpu\":\n",
    "    batch_size = 64\n",
    "    num_workers = 0\n",
    "else:\n",
    "    print(\"unknown device!\")\n",
    "\n",
    "datamodule = EuroSATDataModule(\n",
    "    batch_size=batch_size, \n",
    "    root=\"data\", \n",
    "    num_workers=num_workers, \n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "Experiment with the model and pretrained weights -> https://torchgeo.readthedocs.io/en/stable/tutorials/pretrained_weights.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ClassificationTask(\n",
    "    model=\"resnet50\",\n",
    "    # weights=True, # standard Imagenet\n",
    "    # weights=ResNet18_Weights.SENTINEL2_ALL_MOCO, # or try sentinel 2 all bands\n",
    "    # weights=ResNet18_Weights.SENTINEL2_RGB_MOCO, # or try sentinel 2 rgb bands\n",
    "    weights=ResNet50_Weights.SENTINEL2_ALL_MOCO, # or try sentinel 2 all bands\n",
    "    num_classes=10,\n",
    "    in_channels=13,\n",
    "    loss=\"ce\", \n",
    "    patience=6\n",
    ")\n",
    "\n",
    "# tb_logger = TensorBoardLogger(\"tensorboard_logs\", name=\"eurosat\")\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"eurosat\", \n",
    "    name=\"resnet50_SENTINEL2_ALL_MOCO\", \n",
    "    log_model='all' , # or True\n",
    "    save_dir = \"wandb_logs\"\n",
    ")\n",
    "\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     monitor=\"val_loss\", save_top_k=-1 #  dirpath=default_root_dir, , save_last=True\n",
    "# )\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=6)\n",
    "\n",
    "trainer = Trainer(\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[early_stopping_callback], # checkpoint_callback\n",
    "    min_epochs=5,\n",
    "    max_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger.experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
