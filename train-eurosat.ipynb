{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchgeo.datasets import EuroSAT\n",
    "from torchgeo.datamodules import EuroSATDataModule\n",
    "from torchgeo.transforms import AugmentationSequential, indices\n",
    "from torchgeo.trainers import ClassificationTask\n",
    "from torchgeo.models import ResNet18_Weights\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "seed_everything(543)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the datamodule - validate train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    batch_size = 64\n",
    "    num_workers = 8\n",
    "elif device ==  \"cpu\":\n",
    "    batch_size = 16 # TODO check why this is not picked up\n",
    "    num_workers = 0\n",
    "else:\n",
    "    print(\"unknown device!\")\n",
    "\n",
    "rgb_bands = (\"B04\", \"B03\", \"B02\") # or experiment with all\n",
    "\n",
    "datamodule = EuroSATDataModule(\n",
    "    batch_size=batch_size, \n",
    "    root=\"data\", \n",
    "    num_workers=num_workers, \n",
    "    # bands=rgb_bands, # RE RGB only: https://github.com/microsoft/torchgeo/issues/1634\n",
    "    download=True,\n",
    "    transforms=None,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some validation on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.prepare_data()\n",
    "datamodule.setup('fit')\n",
    "len(datamodule.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('B04', 'B03', 'B02')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataset.bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataset[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = datamodule.train_dataset[0]\n",
    "fig = datamodule.train_dataset.plot(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the model and pretrained weights -> https://torchgeo.readthedocs.io/en/stable/tutorials/pretrained_weights.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ClassificationTask(\n",
    "    model=\"resnet18\",\n",
    "    # weights=True, # standard Imagenet\n",
    "    # weights=ResNet18_Weights.SENTINEL2_ALL_MOCO, # or try sentinel 2 all bands\n",
    "    weights=ResNet18_Weights.SENTINEL2_RGB_MOCO, # or try sentinel 2 rgb bands\n",
    "    num_classes=10,\n",
    "    in_channels=len(datamodule.train_dataset.bands), # make sure to validate\n",
    "    loss=\"ce\", \n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    # dirpath=experiment_dir,\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00,\n",
    "    patience=10,\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"tensorboard_logs\", name=\"eurosat\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    accelerator=device,\n",
    "    logger=logger,\n",
    "    # default_root_dir=experiment_dir,\n",
    "    min_epochs=15,\n",
    "    max_epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping, ModelCheckpoint\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | CrossEntropyLoss | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | test_metrics  | MetricCollection | 0     \n",
      "4 | model         | ResNet           | 11.2 M\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33541376e2804efdb7f2d536a376c4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mean length and number of channels do not match. Got torch.Size([13]) and torch.Size([16, 3, 64, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mtask, datamodule\u001b[39m=\u001b[39;49mdatamodule)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    534\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1021\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m   1020\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1021\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1023\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1050\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1049\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1052\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1054\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:361\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    358\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[1;32m    360\u001b[0m batch \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39m_on_before_batch_transfer(batch, dataloader_idx\u001b[39m=\u001b[39mdataloader_idx)\n\u001b[0;32m--> 361\u001b[0m batch \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mbatch_to_device\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, dataloader_idx\u001b[39m=\u001b[39;49mdataloader_idx)\n\u001b[1;32m    363\u001b[0m step_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_kwargs(batch, batch_idx, dataloader_idx \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    365\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_ready()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 294\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    297\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:270\u001b[0m, in \u001b[0;36mStrategy.batch_to_device\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    268\u001b[0m device \u001b[39m=\u001b[39m device \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_device\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49m_apply_batch_transfer_handler(batch, device\u001b[39m=\u001b[39;49mdevice, dataloader_idx\u001b[39m=\u001b[39;49mdataloader_idx)\n\u001b[1;32m    271\u001b[0m \u001b[39mreturn\u001b[39;00m move_data_to_device(batch, device)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/core/module.py:327\u001b[0m, in \u001b[0;36mLightningModule._apply_batch_transfer_handler\u001b[0;34m(self, batch, device, dataloader_idx)\u001b[0m\n\u001b[1;32m    325\u001b[0m device \u001b[39m=\u001b[39m device \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    326\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_hook(\u001b[39m\"\u001b[39m\u001b[39mtransfer_batch_to_device\u001b[39m\u001b[39m\"\u001b[39m, batch, device, dataloader_idx)\n\u001b[0;32m--> 327\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(\u001b[39m\"\u001b[39;49m\u001b[39mon_after_batch_transfer\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, dataloader_idx)\n\u001b[1;32m    328\u001b[0m \u001b[39mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/core/module.py:315\u001b[0m, in \u001b[0;36mLightningModule._call_batch_hook\u001b[0;34m(self, hook_name, *args)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m         trainer_method \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39m_call_lightning_datamodule_hook\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_method(trainer, hook_name, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    316\u001b[0m hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, hook_name)\n\u001b[1;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m hook(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:166\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(fn):\n\u001b[1;32m    165\u001b[0m     \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningDataModule]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mdatamodule\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 166\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/torchgeo/torchgeo/datamodules/geo.py:140\u001b[0m, in \u001b[0;36mBaseDataModule.on_after_batch_transfer\u001b[0;34m(self, batch, dataloader_idx)\u001b[0m\n\u001b[1;32m    137\u001b[0m         split \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     aug \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_attribute(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m_aug\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maug\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m     batch \u001b[39m=\u001b[39m aug(batch)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/torchgeo/torchgeo/transforms/transforms.py:74\u001b[0m, in \u001b[0;36mAugmentationSequential.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     71\u001b[0m     batch[\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m rearrange(batch[\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mb h w -> b () h w\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m inputs \u001b[39m=\u001b[39m [batch[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_keys]\n\u001b[0;32m---> 74\u001b[0m outputs_list: Union[Tensor, \u001b[39mlist\u001b[39m[Tensor]] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maugs(\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m     75\u001b[0m outputs_list \u001b[39m=\u001b[39m (\n\u001b[1;32m     76\u001b[0m     outputs_list \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs_list, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m [outputs_list]\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     78\u001b[0m outputs: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Tensor] \u001b[39m=\u001b[39m {\n\u001b[1;32m     79\u001b[0m     k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_keys, outputs_list)\n\u001b[1;32m     80\u001b[0m }\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kornia/augmentation/container/augment.py:349\u001b[0m, in \u001b[0;36mAugmentationSequential.forward\u001b[0;34m(self, params, data_keys, *args)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m params:\n\u001b[1;32m    348\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_submodule(param\u001b[39m.\u001b[39mname)\n\u001b[0;32m--> 349\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_op\u001b[39m.\u001b[39;49mtransform(  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    350\u001b[0m         \u001b[39m*\u001b[39;49moutputs, module\u001b[39m=\u001b[39;49mmodule, param\u001b[39m=\u001b[39;49mparam, extra_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextra_args\n\u001b[1;32m    351\u001b[0m     )\n\u001b[1;32m    352\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    353\u001b[0m         \u001b[39m# Make sure we are unpacking a list whilst post-proc\u001b[39;00m\n\u001b[1;32m    354\u001b[0m         outputs \u001b[39m=\u001b[39m [outputs]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kornia/augmentation/container/ops.py:109\u001b[0m, in \u001b[0;36mAugmentationSequentialOps.transform\u001b[0;34m(self, module, param, extra_args, data_keys, *arg)\u001b[0m\n\u001b[1;32m    107\u001b[0m     op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_op(dcate)\n\u001b[1;32m    108\u001b[0m     extra_arg \u001b[39m=\u001b[39m extra_args[dcate] \u001b[39mif\u001b[39;00m dcate \u001b[39min\u001b[39;00m extra_args \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 109\u001b[0m     outputs\u001b[39m.\u001b[39mappend(op\u001b[39m.\u001b[39;49mtransform(inp, module, param\u001b[39m=\u001b[39;49mparam, extra_args\u001b[39m=\u001b[39;49mextra_arg))\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(outputs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kornia/augmentation/container/ops.py:159\u001b[0m, in \u001b[0;36mInputSequentialOps.transform\u001b[0;34m(cls, input, module, param, extra_args)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39minput\u001b[39m: Tensor, module: Module, param: ParamItem, extra_args: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m {}) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(module, (_AugmentationBase, K\u001b[39m.\u001b[39mMixAugmentationBaseV2)):\n\u001b[0;32m--> 159\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m, params\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_instance_module_param(param), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_args)\n\u001b[1;32m    160\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(module, (K\u001b[39m.\u001b[39mcontainer\u001b[39m.\u001b[39mImageSequentialBase,)):\n\u001b[1;32m    161\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mtransform_inputs(\u001b[39minput\u001b[39m, params\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_sequential_module_param(param), extra_args\u001b[39m=\u001b[39mextra_args)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kornia/augmentation/base.py:210\u001b[0m, in \u001b[0;36m_BasicAugmentationBase.forward\u001b[0;34m(self, input, params, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mbatch_prob\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tensor([\u001b[39mTrue\u001b[39;00m] \u001b[39m*\u001b[39m batch_shape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    208\u001b[0m params, flags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_kwargs_to_params_and_flags(params, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflags, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 210\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_func(in_tensor, params, flags)\n\u001b[1;32m    211\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_output_tensor(output, input_shape) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeepdim \u001b[39melse\u001b[39;00m output\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kornia/augmentation/_2d/base.py:125\u001b[0m, in \u001b[0;36mRigidAffineAugmentationBase2D.apply_func\u001b[0;34m(self, in_tensor, params, flags)\u001b[0m\n\u001b[1;32m    122\u001b[0m     flags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflags\n\u001b[1;32m    124\u001b[0m trans_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_transformation_matrix(in_tensor, params, flags)\n\u001b[0;32m--> 125\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_inputs(in_tensor, params, flags, trans_matrix)\n\u001b[1;32m    126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_matrix \u001b[39m=\u001b[39m trans_matrix\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kornia/augmentation/base.py:261\u001b[0m, in \u001b[0;36m_AugmentationBase.transform_inputs\u001b[0;34m(self, input, params, flags, transform, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m in_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_tensor(\u001b[39minput\u001b[39m)\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m to_apply\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 261\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_transform(in_tensor, params, flags, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[1;32m    262\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m to_apply\u001b[39m.\u001b[39many():\n\u001b[1;32m    263\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_non_transform(in_tensor, params, flags, transform\u001b[39m=\u001b[39mtransform)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kornia/augmentation/_2d/intensity/normalize.py:67\u001b[0m, in \u001b[0;36mNormalize.apply_transform\u001b[0;34m(self, input, params, flags, transform)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_transform\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, params: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Tensor], flags: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any], transform: Tensor \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m normalize(\u001b[39minput\u001b[39;49m, flags[\u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m], flags[\u001b[39m\"\u001b[39;49m\u001b[39mstd\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/kornia/enhance/normalize.py:109\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(data, mean, std)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m mean\u001b[39m.\u001b[39mshape \u001b[39mand\u001b[39;00m mean\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m mean\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39mand\u001b[39;00m mean\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m] \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]:\n\u001b[0;32m--> 109\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean length and number of channels do not match. Got \u001b[39m\u001b[39m{\u001b[39;00mmean\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[39m# Allow broadcast on channel dimension\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m std\u001b[39m.\u001b[39mshape \u001b[39mand\u001b[39;00m std\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: mean length and number of channels do not match. Got torch.Size([13]) and torch.Size([16, 3, 64, 64])."
     ]
    }
   ],
   "source": [
    "trainer.fit(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping, ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d13fade32a442795b943e739764620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_AverageAccuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9494212865829468     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_F1Score        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9525926113128662     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_JaccardIndex     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9072655439376831     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_OverallAccuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9525926113128662     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.1797962188720703     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_AverageAccuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9494212865829468    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_F1Score       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9525926113128662    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_JaccardIndex    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9072655439376831    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_OverallAccuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9525926113128662    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.1797962188720703    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.1797962188720703,\n",
       "  'test_AverageAccuracy': 0.9494212865829468,\n",
       "  'test_F1Score': 0.9525926113128662,\n",
       "  'test_JaccardIndex': 0.9072655439376831,\n",
       "  'test_OverallAccuracy': 0.9525926113128662}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=task, datamodule=datamodule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model checkpoint is saved below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epoch=7-step=2032.ckpt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"tensorboard_logs/eurosat/version_0/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
